{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Splitting and Embedding Text Using LangChain"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ffbe2af3006c6e0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "369098d4aab273fb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "with open('files/churchill_speech.txt') as f:\n",
    "    churchill_speech = f.read()\n",
    "    \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a953a8f7d932c2d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "chunks = text_splitter.create_documents([churchill_speech])\n",
    "# print(chunks[2])\n",
    "print(f'Now you have {len(chunks)}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b2c9647dadb2513",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def print_embedding_cost(texts):\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    print(f'Total Tokens: {total_tokens}')\n",
    "    print(f'Embedding Cost in USD: {total_tokens / 1000 * 0.0004:.6f}')\n",
    "    \n",
    "print_embedding_cost(chunks)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "686c4aedd3c52ddd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12f77287f98c1e56",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vector = embeddings.embed_query(chunks[0].page_content)\n",
    "vector"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd8d133bdce0cd7f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inserting the Embedding into a Pinecone Index"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75cb32a38cb27e3d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "pc = pinecone.Pinecone()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "171bf6a977d0c7e9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create Pinecone index"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cd0969d0e6a9b75"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i in pc.list_indexes().names():\n",
    "    print('Deleting all indexes ...', end='')\n",
    "    pc.delete_index(i)\n",
    "    print('Done')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0ac1f59d65ceba8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "index_name = 'churchill-speech'\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    print(f'Creating index {index_name}...')\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric='cosine',\n",
    "        spec=pinecone.PodSpec(\n",
    "            environment='gcp-starter'\n",
    "        )\n",
    "    )\n",
    "    print('Done')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbf7a4e4293bb945",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Upload the vectors to Pinecone using langchain\n",
    "vector_store = Pinecone.from_documents(chunks, embeddings, index_name=index_name)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c79bc5fb5b31332",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Loading the vector store from an existing index\n",
    "load_vector_store = Pinecone.from_existing_index(index_name='churchill-speech', embedding=embeddings)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c48be1189378f56",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Asking Questions (Similarity Search)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ae1a8a2adbe893b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "query = 'Where should we fight?'\n",
    "result = load_vector_store.similarity_search(query)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30c47ec10ffd4796",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for r in result:\n",
    "    print(r.page_content)\n",
    "    print('-'*50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d8094d4466d5ba8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1)\n",
    "\n",
    "# Retrieve the most three similar chunks\n",
    "retriever = load_vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0040a918d1e56e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "query = 'Where should we fight?'\n",
    "answer = chain.invoke(query)\n",
    "print(answer['result'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29d444d7c5f5bfc7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "query2 = 'Who was the king of Belgium at that time?'\n",
    "answer2 = chain.invoke(query2)\n",
    "print(answer2['result'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b4b340ef39357fa",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
