{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "# llm.set_engine(\"davinci-codex\")\n",
    "output = llm.invoke('Explain quantum mechanics in one sentence.', model='gpt-3.5-turbo')\n",
    "print(output.content)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "572d088b81c52ab8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "help(ChatOpenAI)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c2076a7a14af8a5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.schema import(\n",
    "    SystemMessage,\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content='You are a physicist and respond only in German.'),\n",
    "    HumanMessage(content='Explain quantum mechanics in one sentence.')\n",
    "]\n",
    "\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a46f60d85077fab",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Caching LLM Responses\n",
    "In-Memory Cache"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "842f2e447903935a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name='gpt-3.5-turbo-instruct')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71456c694e57bd33",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%time\n",
    "from langchain.cache import InMemoryCache\n",
    "set_llm_cache(InMemoryCache())\n",
    "prompt = 'Tell me a joke that a toddler can understand.'\n",
    "llm.invoke(prompt)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b27bcdc1a5c8f024",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%time\n",
    "llm.invoke(prompt)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60a146f28c9e8d7d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SQLite Caching"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "caa41304257f19c7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))\n",
    "\n",
    "# First request (not in cache, takes longer)\n",
    "llm.invoke(\"Tell me a joke\")\n",
    "\n",
    "# Second request (cached, faster)\n",
    "llm.invoke(\"Tell me a joke\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca299a07e9271e72",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LLM Streaming"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c0f7a4a2d0484bd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "prompt = 'Write a rock song about the Moon and a Raven.'\n",
    "print(llm.invoke(prompt).content)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da72af07655db606",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for chunk in llm.stream(prompt):\n",
    "    print(chunk.content, end='', flush=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c966048440a709f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prompt Templates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c11b38e313852264"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "# from langchain_openai import ChatOpenAI\n",
    "template = '''You are an experience virologist. Write a few sentences about the following virus \"{virus}\" in {language}.'''\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "prompt = prompt_template.format(virus='hiv', language='german')\n",
    "prompt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c0c6d18973400a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)\n",
    "output = llm.invoke(prompt)\n",
    "print(output.content)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5ef2e66970dec62",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ChatPromptTemplates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b72149d3cbb47988"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content='You respond only in the JSON format.'),\n",
    "        HumanMessagePromptTemplate.from_template('Top {n} countries in {area} by population.')\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(n='10', area='Europe')\n",
    "print(messages)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "287e63228f4e4fd7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e436911dbbeb5370",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple Chains"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6d603c4694f5ccd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "template = '''You are an experience virologist. Write a few sentences about the following virus {virus} in {language}.'''\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "output = chain.invoke({'virus': 'HSV', 'language': 'Spanish'})\n",
    "\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec77ef5afa14b2ab",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Another example with a single template value"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa8ad8f7cc7458a5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "template = 'What is the capital of {country}?. List the top 3 places to visit in that city. Use bullet points'\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "country = input('Enter Country: ')\n",
    "output = chain.invoke(country)\n",
    "print(output['text'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f7246a5b16af9ca",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sequential Chains"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0dc51147dd0eebb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "# FIRST LLM\n",
    "llm1 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5)\n",
    "prompt_template1 = PromptTemplate.from_template(\n",
    "    template = 'You are an experienced scientist and Python programmer. Write a function that implements the concept of {concept}.'\n",
    ")\n",
    "\n",
    "chain1 = LLMChain(\n",
    "    llm=llm1,\n",
    "    prompt=prompt_template1\n",
    ")\n",
    "\n",
    "# SECOND LLM\n",
    "llm2 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1.2)\n",
    "prompt_template2 = PromptTemplate.from_template(\n",
    "    template='Given the Python function {function}, describe it as detailed as possible.'\n",
    ")\n",
    "chain2 = LLMChain(\n",
    "    llm=llm2,\n",
    "    prompt=prompt_template2\n",
    ")\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "\n",
    "output = overall_chain.invoke('linear regression')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c144fbab8333ed3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(output['output'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efc85e00b42d3883",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LangChain Agents in Action: Python REPL"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f738f5b0061419e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pip install -q langchain_experimental"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e853b249cc95b6b1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LangChain Tools: DuckDuckGp and Wikipedia"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21ae3b3b0470e486"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pip install -q duckduckgo-search"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c83e578b310646aa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "output = search.invoke('Where was the Freddie Mercury born?')\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9023b9a92fa02c28",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "search.name"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17f33bf984f9ca23",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "search.description"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66299b2488bea653",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "search = DuckDuckGoSearchResults()\n",
    "output = search.run('Freddie Mercury and Queen')\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8eb6d04a5b6d2eb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(region='de-de', max_results=3, safesearch='moderate')\n",
    "search = DuckDuckGoSearchResults(api_wrapper=wrapper, source='news')\n",
    "output = search.run('Berlin')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9147eb2b918a50c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(output)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38f0a0a405054284",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = r'snippet: (.*?), title: (.*?), link: (.*?)\\],'\n",
    "matches = re.findall(pattern, output, re.DOTALL)\n",
    "\n",
    "for snipper, title, link in matches:\n",
    "    print(f'Snippet: {snipper}\\nTitle: {title}\\nLink: {link}\\n')\n",
    "    print('-' * 50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "237618eb59c8344",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pip install -q wikipedia"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc778e3e091198e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.tools import WikipediaQueryRun"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3bc127ae9d28f3c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=5000)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "wiki.invoke({'query': 'llamaindex'})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3da7d0096689d82",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "wiki.invoke('Google Gemini')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efd8661300e94bb2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating a ReAct Agent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6748c4d2526320ae"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pip install langchainhub -q"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bca8c7ac8be62e08",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, Tool, initialize_agent, create_react_agent\n",
    "from langchain.tools import DuckDuckGoSearchRun, WikipediaQueryRun\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)\n",
    "\n",
    "template = '''\n",
    "Answer the following questions as best you can.\n",
    "Questions: {q}\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "prompt = hub.pull('hwchase17/react')\n",
    "# print(type(prompt))\n",
    "# print(prompt.input_variables)\n",
    "# print(prompt.template)\n",
    "\n",
    "# 1. Python REPL Tool (for executing Python code)\n",
    "python_repl = PythonREPLTool()\n",
    "python_repl_tool = Tool(\n",
    "    name='Python REPL',\n",
    "    func=python_repl.run,\n",
    "    description='Useful when you need to use Python to answer a question. You should input Python code.'\n",
    ")\n",
    "\n",
    "# 2. Wikipedia Tool (for searching Wikipedia)\n",
    "api_wrapper = WikipediaAPIWrapper()\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "wikipedia_tool = Tool(\n",
    "    name='Wikipedia',\n",
    "    func=wikipedia.run,\n",
    "    description='Useful for when you look up to a topic, country, or person on Wikipedia'\n",
    ")\n",
    "\n",
    "# 3. DuckDuckGo Search Tool (for general web searches)\n",
    "search = DuckDuckGoSearchRun()\n",
    "duckduckgo_tool = Tool(\n",
    "    name='DucDuckGo Search',\n",
    "    func=search.run,\n",
    "    description='Useful for when you need to perform an internet search to find information that another tool can\\'t provide'\n",
    ")\n",
    "\n",
    "tools = [python_repl_tool, wikipedia_tool, duckduckgo_tool]\n",
    "\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executer = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=10\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "142630aa6359af16",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "question = 'Generate the first 20 numbers in the Fibonacci series.'\n",
    "output = agent_executer.invoke({\n",
    "    'input': prompt_template.format(q=question)\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1789aac38d05bb69",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(output['input'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90cf14197eb83075",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(output['output'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "556949aca28b2f39",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "question2 = 'Who is the current prime minister of the UK?'\n",
    "output2 = agent_executer.invoke({\n",
    "    'input': prompt_template.format(q=question2)\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed00772505a436ec",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "question3 = 'Tell me about Napolean Bonaparte early life'\n",
    "output3 = agent_executer.invoke({\n",
    "    'input': prompt_template.format(q=question3)\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d717770cb611ac7a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(output3['input'])\n",
    "print(output3['output'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f40031618d4a7d30",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "79419d87ba66df29"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
