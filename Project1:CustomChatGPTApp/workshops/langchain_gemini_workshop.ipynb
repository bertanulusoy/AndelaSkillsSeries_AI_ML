{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LangChain and Google's Gemini"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95975b7565e3216c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pip install -q langchain-google-genai"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19be84f801531c14",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# to upgrade\n",
    "# !pip install --upgrade -q langchain-google-genai"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6fa35c88fc40535",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pip show langchain-google-genai"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7676bbf9e9468d64",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pip install -q google-generativeai"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68117d17b97be7fc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the API key\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76aee9b6e625732d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# If you can't load the API key, you can provide it manually\n",
    "import getpass\n",
    "import os\n",
    "if 'MY_GOOGLE_API_KEY' not in os.environ:\n",
    "    os.environ['MY_GOOGLE_API_KEY'] = getpass.getpass('Provide your Google API Key: ')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2d237140a3a543e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "for model in genai.list_models():\n",
    "    print(model.name)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "903e76b0e427621f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Integrating Gemini with LangChain"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b2b3308ed434140"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-pro', temperature=0.9)\n",
    "response = llm.invoke('Write a paragraph about life on Mars in year 2100.')\n",
    "print(response.content)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96017042f78d3ea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-pro')\n",
    "\n",
    "prompt = PromptTemplate.from_template('You are a content creator. Write me a tweet about {topic}')\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "topic = 'Why will AI change the World'\n",
    "response = chain.invoke(input=topic)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7738774edc8f7316",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(response['topic'])\n",
    "print()\n",
    "print(response['text'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ddc4a749a746ae5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# System Prompt and Streaming"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ade0d94fc54bfbf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-pro', convert_system_message_to_human=True)\n",
    "\n",
    "output = llm.invoke(\n",
    "    [\n",
    "        SystemMessage(content='Answer only YES or NO in French.'),\n",
    "        HumanMessage(content='Is cat a mammal?')\n",
    "    ]\n",
    ")\n",
    "output.content"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "215fc92e0c569e43",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Streaming"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0f6077cabb294c5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model='gemini-pro', temperature=0)\n",
    "prompt = 'Write a scientific paper outlining the mathematical foundation of our universe.'\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45d2bd6f82ddf7aa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for chunk in llm.stream(prompt):\n",
    "    print(chunk.content, end='')\n",
    "    print('-' * 100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6f9d878383dd85b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multimodal AI with Gemini Pro Vision"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28bbb492a3e5fbe9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pip install -q pillow"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "803384bab19ce937",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.open('match.jpg')\n",
    "img"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e7c8cc57d3871cf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-pro-vision')\n",
    "prompt = 'What is in this image?'\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {'type': 'text', 'text': prompt},\n",
    "        {'type': 'image_url', 'image_url': img}\n",
    "    ]\n",
    ")\n",
    "response = llm.invoke([message])\n",
    "print(response.content)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b85b9e9394c2ca9b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def ask_gemini(text, image, model='gemini-pro-vision'):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param text: The text query or prompt for llm  \n",
    "    :param image: The image\n",
    "    :param model: The name of the Gemini LLM model\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    llm = ChatGoogleGenerativeAI(model=model)\n",
    "    prompt = 'What is in this image?'\n",
    "    message = HumanMessage(\n",
    "        content=[\n",
    "            {'type': 'text', 'text': text},\n",
    "            {'type': 'image_url', 'image_url': image}\n",
    "        ]\n",
    "    )\n",
    "    response = llm.invoke([message])\n",
    "    return response.content"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e800f45c7877618",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "response = ask_gemini('What is this sport? How can I identify the sport in this picture?', image=img)\n",
    "print(response)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ee02d96f0861421",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "response = ask_gemini('How many players can you identify in each team?', image=img)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb16746613423edd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.display import Image\n",
    "image_url = 'https://picsum.photos/id/40/4106/2806'\n",
    "content = requests.get(image_url).content\n",
    "image_data = Image(content)\n",
    "image_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f617318563ab5de",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "response = ask_gemini('Describe this image as detailed as possible', image_url)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49a64a84ed0dd1c7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gemini Safety Settings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a18a6de292a7ccd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_google_genai import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "llm2 = ChatGoogleGenerativeAI(\n",
    "    model = 'gemini-pro',\n",
    "    safety_settings={\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8f88de643bc2bd7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
